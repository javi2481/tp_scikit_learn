# ğŸ” 07 - ValidaciÃ³n cruzada e hiperparÃ¡metros

## ğŸ¯ Â¿Por quÃ© validar?

Al entrenar un modelo, queremos asegurarnos de que **generaliza bien** y no simplemente memoriza los datos de entrenamiento.  
AquÃ­ entra en juego la **validaciÃ³n cruzada**, una tÃ©cnica para evaluar la robustez de un modelo.

---

## ğŸ”„ Â¿QuÃ© es la validaciÃ³n cruzada?

Consiste en dividir los datos en varias particiones o *folds*. El modelo se entrena en algunos folds y se prueba en otros.  
La variante mÃ¡s comÃºn es la **k-fold cross-validation** (por ejemplo, k=5).

âœ… Ventajas:
- EvalÃºa el rendimiento promedio
- Disminuye el riesgo de overfitting
- Aumenta la confiabilidad del modelo

ğŸ”— [ExplicaciÃ³n detallada en Scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html)

---

## ğŸ”§ Ajuste de hiperparÃ¡metros

Los **hiperparÃ¡metros** no se aprenden del dataset, sino que se configuran manualmente o mediante bÃºsqueda.  
Ejemplos: `n_estimators`, `max_depth`, `kernel`, `alpha`.

### Herramientas de Scikit-learn:

- `GridSearchCV`: prueba todas las combinaciones posibles ğŸ”  
- `RandomizedSearchCV`: selecciona combinaciones al azar ğŸ²  
- `HalvingGridSearchCV`: bÃºsqueda eficiente y escalable âš¡

---

## ğŸ“‰ Ejemplo: curva de validaciÃ³n

```python
from sklearn.datasets import load_digits
from sklearn.svm import SVC
from sklearn.model_selection import validation_curve
import numpy as np
import matplotlib.pyplot as plt

X, y = load_digits(return_X_y=True)
param_range = np.logspace(-6, -1, 5)

train_scores, test_scores = validation_curve(
    SVC(), X, y, param_name="gamma", param_range=param_range, cv=5, scoring="accuracy"
)

plt.plot(param_range, test_scores.mean(axis=1))
plt.xscale("log")
plt.title("Curva de validaciÃ³n")
plt.xlabel("gamma")
plt.ylabel("Accuracy")
plt.show()
```

---

## ğŸ“Š Curva de aprendizaje

Permite ver cÃ³mo se comporta un modelo a medida que se entrena con mÃ¡s datos.

```python
from sklearn.model_selection import learning_curve

train_sizes, train_scores, test_scores = learning_curve(
    SVC(gamma=0.001), X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 5)
)
```

---

## âœ… ConclusiÃ³n

La validaciÃ³n cruzada y el ajuste de hiperparÃ¡metros son pasos clave en el desarrollo de modelos.  
Permiten evaluar de forma mÃ¡s justa, evitar errores y encontrar la mejor configuraciÃ³n posible.
