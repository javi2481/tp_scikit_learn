# üß© 04 - Pipelines y Preprocesamiento de Modelos de Machine Learning

## 1Ô∏è‚É£ Introducci√≥n üöÄ

El proceso de Machine Learning (ML) no se limita al entrenamiento de un modelo: implica una serie de pasos bien organizados que transforman datos crudos en predicciones √∫tiles.  
Uno de los enfoques m√°s potentes para manejar esta complejidad es el uso de **pipelines**, que permiten automatizar, reproducir y versionar el flujo completo.

> üéØ Un buen pipeline garantiza que las transformaciones aplicadas durante el desarrollo tambi√©n se apliquen de forma id√©ntica en producci√≥n.

---

## 2Ô∏è‚É£ ¬øQu√© es un Pipeline de Machine Learning? üõ†Ô∏è

Un **pipeline de ML** es una secuencia automatizada de pasos que organiza el flujo de trabajo completo:

### üîÑ Etapas t√≠picas:

1. **üì• Ingesta de datos**
2. **üßπ Preprocesamiento**
3. **‚úÇÔ∏è Divisi√≥n del dataset**
4. **ü§ñ Entrenamiento del modelo**
5. **üìä Evaluaci√≥n**
6. **üöÄ Despliegue**
7. **üìà Monitoreo**

---

## üîß Herramientas populares en producci√≥n

- **Gesti√≥n de pipelines**: `Scikit-learn`, `MLflow`, `Kubeflow`, `Airflow`  
- **Versionado**: `DVC`, `MLflow`  
- **Automatizaci√≥n**: `Jenkins`, `GitHub Actions`  
- **Tracking de experimentos**: `Weights & Biases`, `MLflow`

---

## 3Ô∏è‚É£ Etapas del Preprocesamiento de Datos üßº

1. **üßΩ Limpieza de datos**
2. **üß© Imputaci√≥n de valores faltantes**
3. **üìè Escalado de variables num√©ricas**
4. **üè∑Ô∏è Codificaci√≥n de variables categ√≥ricas**
5. **üß† Feature Engineering**
6. **‚úÇÔ∏è Selecci√≥n de variables**

---

## 4Ô∏è‚É£ Buenas Pr√°cticas üß†

‚úÖ Automatizar todo dentro del pipeline  
‚úÖ Aplicar las mismas transformaciones en desarrollo y producci√≥n  
‚úÖ Evitar *data leakage*  
‚úÖ Separar preprocesamiento del modelado  
‚úÖ Serializar el pipeline completo  
‚úÖ Versionar todo lo que se entrena

---

## 5Ô∏è‚É£ Ejemplo pr√°ctico con Scikit-learn ü§ñ

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import pandas as pd

# Cargar datos
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = iris.target

# Dividir dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocesamiento num√©rico
numeric_features = X.columns.tolist()
numeric_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

preprocessor = ColumnTransformer([
    ('num', numeric_transformer, numeric_features)
])

# Pipeline completo
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
])

# Entrenar y evaluar
pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)
print(f"Accuracy: {accuracy_score(y_test, y_pred):.3f}")
```

---

## 6Ô∏è‚É£ Conclusi√≥n üéì

Los pipelines permiten construir flujos de trabajo robustos, reutilizables y adaptables tanto en desarrollo como en producci√≥n.

> ‚úÖ Automatizaci√≥n + reproducibilidad + buenas pr√°cticas = proyectos de ML profesionales y sostenibles.
