# ğŸ“ 06 - MÃ©tricas de evaluaciÃ³n

Evaluar un modelo de Machine Learning es tan importante como entrenarlo.  
Las mÃ©tricas nos ayudan a entender quÃ© tan bien estÃ¡ funcionando el modelo y si realmente cumple con su propÃ³sito.

---

## ğŸŸ© ClasificaciÃ³n

Se utiliza cuando queremos predecir **categorÃ­as** o **etiquetas discretas** (por ejemplo: "spam" vs. "no spam").

### MÃ©tricas principales:

- **Accuracy (PrecisiÃ³n global)** âœ…  
- **Precision (PrecisiÃ³n positiva)** ğŸ¯  
- **Recall (Sensibilidad)** ğŸ”  
- **F1-score** âš–ï¸  
- **Matriz de confusiÃ³n** ğŸ”²  

```python
from sklearn.metrics import confusion_matrix, classification_report

y_true = [1, 0, 1, 1, 0, 1]
y_pred = [1, 0, 1, 0, 0, 1]

# Imprimimos la matriz de confusiÃ³n para ver verdaderos y falsos positivos/negativos
print(confusion_matrix(y_true, y_pred))
# Mostramos precisiÃ³n, recall, F1-score por clase
print(classification_report(y_true, y_pred))
```

---

## ğŸ“Š RegresiÃ³n

Se usa cuando el objetivo es predecir un **valor numÃ©rico continuo**.

- **MAE (Mean Absolute Error)** ğŸ“‰  
- **MSE (Mean Squared Error)** ğŸ“ˆ  
- **RMSE (Root Mean Squared Error)**  
- **RÂ² Score (Coeficiente de determinaciÃ³n)** ğŸ”¢  

---

## ğŸ§ª Visualizaciones complementarias

ğŸ”— [ROC and AUC - Scikit-learn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html)

- **Curvas ROC** y **AUC**  
- **Curvas de validaciÃ³n y aprendizaje**

ğŸ”— [Scikit-learn - MÃ©tricas y scoring](https://scikit-learn.org/stable/modules/model_evaluation.html)

---

## âœ… ConclusiÃ³n

Elegir la mÃ©trica adecuada depende del tipo de problema.  
Medir correctamente el rendimiento permite mejorar modelos, comparar alternativas y tomar decisiones basadas en datos reales.
